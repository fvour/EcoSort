{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 01:26:28] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 01:26:28] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 01:26:54] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 01:27:14] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 01:27:23] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 01:27:49] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [04/Jan/2025 01:27:59] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from flask_cors import CORS\n",
    "from rembg import remove\n",
    "from PIL import Image\n",
    "import io\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\TisGJRRR\\\\EcoSort_Revision\")\n",
    "model_path = \"Models/EcoSortV3.h5\"\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "UPLOAD_FOLDER = 'uploads'\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "\n",
    "class_labels = ['cardboard', 'glass', 'metal', 'paper', 'plastic']\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "def generate_unique_filename(original_filename):\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    ext = original_filename.rsplit('.', 1)[1].lower()\n",
    "    return f\"image_{timestamp}.{ext}\"\n",
    "\n",
    "def remove_background(image_path):\n",
    "    \"\"\"Remove the background using rembg.\"\"\"\n",
    "    try:\n",
    "        with open(image_path, 'rb') as input_file:\n",
    "            input_data = input_file.read()\n",
    "\n",
    "        # Remove the background\n",
    "        output_data = remove(input_data)\n",
    "\n",
    "        # Convert the output to an image\n",
    "        output_image = Image.open(io.BytesIO(output_data))\n",
    "        output_image_path = image_path.rsplit('.', 1)[0] + '_no_bg.png'\n",
    "        output_image.save(output_image_path)\n",
    "\n",
    "        return output_image_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error in remove_background: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def predict_trash_class(image_path):\n",
    "    try:\n",
    "        img = image.load_img(image_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        predictions = model.predict(x)\n",
    "        predicted_class_index = np.argmax(predictions)\n",
    "        predicted_class = class_labels[predicted_class_index]\n",
    "        certainty = float(predictions[0][predicted_class_index] * 100)\n",
    "\n",
    "        return predicted_class, certainty\n",
    "    except Exception as e:\n",
    "        print(f\"Error in predict_trash_class: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def safe_file_removal(filepath):\n",
    "    \"\"\"Safely remove a file if it exists.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(filepath):\n",
    "            os.remove(filepath)\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing file {filepath}: {str(e)}\")\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if 'image' not in request.files:\n",
    "        return jsonify({'error': 'No image provided'}), 400\n",
    "\n",
    "    file = request.files['image']\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if not allowed_file(file.filename):\n",
    "        return jsonify({'error': 'Invalid file type. Allowed types: png, jpg, jpeg'}), 400\n",
    "\n",
    "    try:\n",
    "        # Generate unique filename\n",
    "        filename = generate_unique_filename(secure_filename(file.filename))\n",
    "        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        \n",
    "        # Save uploaded file\n",
    "        file.save(filepath)\n",
    "\n",
    "        # Process image\n",
    "        image_no_bg_path = remove_background(filepath)\n",
    "        predicted_class, certainty = predict_trash_class(image_no_bg_path)\n",
    "\n",
    "        # Clean up files\n",
    "        safe_file_removal(filepath)\n",
    "        safe_file_removal(image_no_bg_path)\n",
    "\n",
    "        return jsonify({\n",
    "            'class': predicted_class,\n",
    "            'certainty': certainty\n",
    "        }), 200\n",
    "\n",
    "    except Exception as e:\n",
    "        # Clean up files in case of error\n",
    "        if 'filepath' in locals():\n",
    "            safe_file_removal(filepath)\n",
    "        if 'image_no_bg_path' in locals():\n",
    "            safe_file_removal(image_no_bg_path)\n",
    "        \n",
    "        error_message = str(e)\n",
    "        print(f\"Error processing image: {error_message}\")\n",
    "        return jsonify({'error': f'Error processing image: {error_message}'}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
